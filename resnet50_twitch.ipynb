{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50-twitch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwwjjvAWGwnvE7Z6Ts5kBO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb576b9c9f0c49a598435b1e67c0f334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0215e025a394515bf013de728446f92",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_194f79abce41476881dbb50448d1bc6b",
              "IPY_MODEL_a1920ff55a254e59afcb7a78bdb93cfe",
              "IPY_MODEL_68d60033e190424cb6ac8365a6eb79ac"
            ]
          }
        },
        "a0215e025a394515bf013de728446f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "194f79abce41476881dbb50448d1bc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9c2e8887e8a4c9b90917ac4966b051d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b231fe6670744030b201cec896c249ef"
          }
        },
        "a1920ff55a254e59afcb7a78bdb93cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d3aa5740494a456dae9e4ee928dbb2d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_972a01d8e5494fc19872db0074c36fab"
          }
        },
        "68d60033e190424cb6ac8365a6eb79ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_000fb638bed24fc1a60efd7d2b3bac87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:05&lt;00:00, 33897026.85it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8037cda136bf4d3c98eeffa3aef0db21"
          }
        },
        "b9c2e8887e8a4c9b90917ac4966b051d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b231fe6670744030b201cec896c249ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3aa5740494a456dae9e4ee928dbb2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "972a01d8e5494fc19872db0074c36fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "000fb638bed24fc1a60efd7d2b3bac87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8037cda136bf4d3c98eeffa3aef0db21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-resnet-twitch/blob/main/resnet50_twitch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6G4Wt9QpD7w",
        "outputId": "6a62b9e8-f7b3-4562-ca94-d72513e405f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 10 01:46:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "import torchinfo\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rlSjbBF_qaG_",
        "outputId": "b432bb17-19c8-4c44-86ee-1ca72d91addc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading\n",
        "\n",
        "Let's import CIFAR10 to build a ResNet50 model on to fit."
      ],
      "metadata": {
        "id": "sHrHQ4Clsu4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "# Setup transform to preprocess images\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     # Normalize to 0.5 mean and 0.5 std across all 3 colour channels of images\n",
        "     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "# Load training data\n",
        "train_data = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                              # num workers defines how many CPU cores to use to load data\n",
        "                              # usually more is better... though you may jam your machine if you use too much...\n",
        "                              shuffle=True, num_workers=NUM_WORKERS)\n",
        "\n",
        "# Load testing data\n",
        "test_data = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "bb576b9c9f0c49a598435b1e67c0f334",
            "a0215e025a394515bf013de728446f92",
            "194f79abce41476881dbb50448d1bc6b",
            "a1920ff55a254e59afcb7a78bdb93cfe",
            "68d60033e190424cb6ac8365a6eb79ac",
            "b9c2e8887e8a4c9b90917ac4966b051d",
            "b231fe6670744030b201cec896c249ef",
            "d3aa5740494a456dae9e4ee928dbb2d8",
            "972a01d8e5494fc19872db0074c36fab",
            "000fb638bed24fc1a60efd7d2b3bac87",
            "8037cda136bf4d3c98eeffa3aef0db21"
          ]
        },
        "id": "H1y6D3x6q6Yw",
        "outputId": "62824f69-ac1a-4fcc-8671-f8324f359789"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb576b9c9f0c49a598435b1e67c0f334",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DzfDWvzs81Z",
        "outputId": "7d252969-0767-4350-bf8e-1935aaf34a5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "random_idx = random.sample(list(range(len(train_data))), k=1)\n",
        "print(random_idx)\n",
        "image, label = train_data[random_idx[0]]\n",
        "print(image.shape)\n",
        "image = image.permute(1, 2, 0) / 2 + 0.5 # change image axis order (3, 32, 32) -> (32, 32, 3) & unormalize\n",
        "print(image.shape)\n",
        "plt.imshow(image)\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "bKQfldnOtCqM",
        "outputId": "fef0df40-0948-4445-c755-0c434fbf3559"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15593]\n",
            "torch.Size([3, 32, 32])\n",
            "torch.Size([32, 32, 3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "We're going to be replicating the ResNet50 model from the classic \"Deep Residual Learning for Image Recognition\" paper: https://arxiv.org/pdf/1512.03385.pdf\n",
        "\n",
        "Good implementation here: https://gist.github.com/nikogamulin/7774e0e3988305a78fd73e1c4364aded"
      ],
      "metadata": {
        "id": "iwUgiJqAuaqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "  def __init__(self, in_features, out_features, stride_size=2, is_identity=True):\n",
        "    super().__init__()\n",
        "    self.is_identity = is_identity\n",
        "    self.expansion = 4 # how much to multiply the output channel by (e.g. 64 -> 256, 128 -> 512)\n",
        "    self.conv1 = nn.Conv2d(in_channels=in_features, \n",
        "                           out_channels=out_features,\n",
        "                           kernel_size=1,\n",
        "                           stride=1,\n",
        "                           padding=1)\n",
        "\n",
        "    self.batch_norm1 = nn.BatchNorm2d(out_features)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=out_features, \n",
        "                            out_channels=out_features, \n",
        "                            kernel_size=3,\n",
        "                            stride=2, # middle (3x3 has the increased stride)\n",
        "                            padding=1)\n",
        "\n",
        "    self.batch_norm2 = nn.BatchNorm2d(out_features)\n",
        "\n",
        "    # Increase out features for last layer in block\n",
        "    increased_out_features = out_features * self.expansion\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=out_features,\n",
        "                           out_channels=increased_out_features,\n",
        "                           kernel_size=1,\n",
        "                           stride=1,\n",
        "                           padding=0)\n",
        "\n",
        "    self.batch_norm3 = nn.BatchNorm2d(increased_out_features)\n",
        "\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    self.identity_downsample = nn.Sequential(nn.Conv2d(in_channels=out_features,\n",
        "                                                       out_channels=increased_out_features,\n",
        "                                                       kernel_size=1,\n",
        "                                                       stride=2,\n",
        "                                                       padding=1),\n",
        "                                             nn.BatchNorm2d(increased_out_features))\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "    print(identity.shape)\n",
        "    print(identity.shape)\n",
        "    print(self.is_identity)\n",
        "\n",
        "    # Block 1\n",
        "    out = self.conv1(x)\n",
        "    out = self.batch_norm1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    # Block 2\n",
        "    out = self.conv2(out)\n",
        "    out = self.batch_norm2(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    # Block 3\n",
        "    out = self.conv3(out)\n",
        "    out = self.batch_norm3(out)\n",
        "    print(f\"Out shape: {out.shape}\")\n",
        "\n",
        "    if self.is_identity:\n",
        "      print(\"Is identity... downsampling...\")\n",
        "      identity = self.identity_downsample(identity)\n",
        "      print(f\"Identity shape: {identity.shape}\")\n",
        "\n",
        "    out += identity\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "OacBetOF4Y_l"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the ResNet50 model\n",
        "model = nn.Sequential()\n",
        "model.add_module(\"Conv1\", nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3))\n",
        "model.add_module(\"BatchNorm1\", nn.BatchNorm2d(num_features=64))\n",
        "model.add_module(\"ReLU1\", nn.ReLU(inplace=True))\n",
        "model.add_module(\"MaxPool1\", nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
        "previous_feature_size = 64\n",
        "for feature_size in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "  print(f\"Feature size: {feature_size}\")\n",
        "  if previous_feature_size == feature_size:\n",
        "    stride_size = 1\n",
        "    is_identity = False\n",
        "  else:\n",
        "    stride_size = 2\n",
        "    is_identity = True\n",
        "  print(f\"Stride size: {stride_size}\")\n",
        "  print(f\"Is identity? {is_identity}\")\n",
        "  model.add_module(f\"{feature_size}_block\", \n",
        "                   ResNetBlock(in_features=feature_size, \n",
        "                               out_features=feature_size, \n",
        "                               stride_size=stride_size,\n",
        "                               is_identity=True))\n",
        "  previous_feature_size = feature_size\n",
        "model.add_module(\"avg_pool\", nn.AdaptiveAvgPool2d((1, 1)))\n",
        "model.add_module(\"fully_connected\", nn.Linear(in_features=previous_feature_size, out_features=len(class_names)))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZLkCeFk4ZkR",
        "outputId": "ce52daaf-d065-4fed-bfab-397654d2eb58"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature size: 64\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 64\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 64\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 128\n",
            "Stride size: 2\n",
            "Is identity? True\n",
            "Feature size: 128\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 128\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 128\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 256\n",
            "Stride size: 2\n",
            "Is identity? True\n",
            "Feature size: 256\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 256\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 256\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 256\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 256\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 512\n",
            "Stride size: 2\n",
            "Is identity? True\n",
            "Feature size: 512\n",
            "Stride size: 1\n",
            "Is identity? False\n",
            "Feature size: 512\n",
            "Stride size: 1\n",
            "Is identity? False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (Conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "  (BatchNorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (ReLU1): ReLU(inplace=True)\n",
              "  (MaxPool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (64_block): ResNetBlock(\n",
              "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
              "    (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (batch_norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (identity_downsample): Sequential(\n",
              "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1))\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (128_block): ResNetBlock(\n",
              "    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
              "    (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (batch_norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (identity_downsample): Sequential(\n",
              "      (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (256_block): ResNetBlock(\n",
              "    (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
              "    (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (identity_downsample): Sequential(\n",
              "      (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1))\n",
              "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (512_block): ResNetBlock(\n",
              "    (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
              "    (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (batch_norm3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (identity_downsample): Sequential(\n",
              "      (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1))\n",
              "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fully_connected): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.unsqueeze(train_data[0][0].to(device), dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WqyqKozjLgp3",
        "outputId": "d250a190-cf67-45c5-a9fa-0df272c45aef"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 8, 8])\n",
            "torch.Size([1, 64, 8, 8])\n",
            "True\n",
            "Out shape: torch.Size([1, 256, 5, 5])\n",
            "Is identity... downsampling...\n",
            "Identity shape: torch.Size([1, 256, 5, 5])\n",
            "torch.Size([1, 256, 5, 5])\n",
            "torch.Size([1, 256, 5, 5])\n",
            "True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-177-5650c016711d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-175-18786bbfbf73>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Block 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 128, 1, 1], expected input[1, 256, 5, 5] to have 128 channels, but got 256 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model, input_size=(BATCH_SIZE, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SJE9JhZqKO-A",
        "outputId": "cb96e18c-02c1-4512-a8c7-42870df039ff"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 64, 56, 56])\n",
            "torch.Size([32, 64, 56, 56])\n",
            "True\n",
            "Out shape: torch.Size([32, 256, 29, 29])\n",
            "Is identity... downsampling...\n",
            "Identity shape: torch.Size([32, 256, 29, 29])\n",
            "torch.Size([32, 256, 29, 29])\n",
            "torch.Size([32, 256, 29, 29])\n",
            "True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-175-18786bbfbf73>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Block 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 128, 1, 1], expected input[32, 256, 29, 29] to have 128 channels, but got 256 channels instead",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-f8ad679802fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchinfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m     summary_list = forward_pass(\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_forward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m     \u001b[0mformatting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFormattingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;34m\"Failed to run torchinfo. See above stack traces for more details. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;34mf\"Executed layers up to: {executed_layers}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         ) from e\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Conv2d: 1, BatchNorm2d: 1, ReLU: 1, MaxPool2d: 1, ResNetBlock: 1, Conv2d: 2, BatchNorm2d: 2, ReLU: 2, Conv2d: 2, BatchNorm2d: 2, ReLU: 2, Conv2d: 2, BatchNorm2d: 2, Sequential: 2, Conv2d: 3, BatchNorm2d: 3, ReLU: 2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2usSwj6BKcS6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}